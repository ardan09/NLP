{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP02iF56UvuiDAyB29Kn79c"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mkmE91B4ekwo"},"source":["# Чанкинг - разбиение текстовых данных на информационные блоки"]},{"cell_type":"code","metadata":{"id":"4fTOhbbweJMs"},"source":["import nltk \n","import numpy as np \n","from nltk.corpus import brown"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWrhhX9PjUUl","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1601437385886,"user_tz":-180,"elapsed":2625,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"4c1d81c3-99f7-4164-e777-03ec09819347"},"source":["nltk.download('brown')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ebRLZ2j3fg0S"},"source":["# Разбиение текста на блоки по N слов\n","def chunker(input_data, N):\n","  '''input_data - текст, N - кол-во слов\n","  '''\n","  input_words = input_data.split(' ')\n","  output = []\n","  cur_chunk = []\n","  count = 0 \n","  for word in input_words: \n","    cur_chunk.append(word)\n","    count += 1 \n","    if count == N:\n","      output.append(' '.join(cur_chunk))\n","      count, cur_chunk = 0, []\n","  output.append(' '.join(cur_chunk))\n","\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTkd4hpPgDiT","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1601411389272,"user_tz":-180,"elapsed":710,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"a9be4be2-3d27-4a0e-e2b4-b5cf5f693877"},"source":["if __name__ == '__main__':\n","  # Чтение первых 12 тыс слов из коллекции Brown\n","  input_data = ' '.join(brown.words()[:12000])\n","  \n","  # Определение количества слов в каждом блоке \n","  chunk_size = 700\n","\n","  chunks = chunker(input_data, chunk_size)\n","  print('\\nNumber of text chunks =', len(chunks), '\\n')\n","  for i, chunk in enumerate(chunks):\n","    print('Chunk', i+1, '==>', chunk[:50])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Number of text chunks = 18 \n","\n","Chunk 1 ==> The Fulton County Grand Jury said Friday an invest\n","Chunk 2 ==> '' . ( 2 ) Fulton legislators `` work with city of\n","Chunk 3 ==> . Construction bonds Meanwhile , it was learned th\n","Chunk 4 ==> , anonymous midnight phone calls and veiled threat\n","Chunk 5 ==> Harris , Bexar , Tarrant and El Paso would be $451\n","Chunk 6 ==> set it for public hearing on Feb. 22 . The proposa\n","Chunk 7 ==> College . He has served as a border patrolman and \n","Chunk 8 ==> of his staff were doing on the address involved co\n","Chunk 9 ==> plan alone would boost the base to $5,000 a year a\n","Chunk 10 ==> nursing homes In the area of `` community health s\n","Chunk 11 ==> of its Angola policy prove harsh , there has been \n","Chunk 12 ==> system which will prevent Laos from being used as \n","Chunk 13 ==> reform in recipient nations . In Laos , the admini\n","Chunk 14 ==> . He is not interested in being named a full-time \n","Chunk 15 ==> said , `` to obtain the views of the general publi\n","Chunk 16 ==> '' . Mr. Reama , far from really being retired , i\n","Chunk 17 ==> making enforcement of minor offenses more effectiv\n","Chunk 18 ==> to tell the people where he stands on the tax issu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FE9aZqOKjyA9"},"source":["text = '''\n","Long Short Term Memory cells are like mini neural networks designed to allow for memory in a larger neural network. This is achieved through the use of a recurrent node inside the LSTM cell. This node has an edge looping back on itself with a weight of one, meaning at every feedfoward iteration the cell can hold onto information from the previous step, as well as all previous steps. Since the looping connection’s weight is one, old memories wont fade over time like they would in traditional RNNs.\n","LTSMs and recurrent neural networks are as a result good at working with time series data thanks to their ability to remember the past. By storing some of the old state in these recurrent nodes, RNNs and LSTMs can reason about current information as well as information the network had seen one, ten or a thousand steps ago. Even better, I don’t have to write my own implementation of an LSTM cell; they’re a default layer in Tensorflow’s Keras.\n","So I had my plan; to use LSTMs and Keras to predict the stock market, and perhaps even make some money. The good thing about stock price history is that it’s basically a well labelled pre formed dataset. After some googling I found a service called AlphaVantage. They offered the daily price history of NASDAQ stocks for the past 20 years. This included the open, high, low, close and volume of trades for each day, from today all the way back up to 1999. Even better, a python wrapper exists for the service. I got my free API key from the website and downloaded Microsofts daily stock history.\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWWoM7xnkNHo","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1601437458879,"user_tz":-180,"elapsed":2605,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"8976c99b-75a6-408b-aa40-0a3d723e9301"},"source":["len(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1545"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"t04KTIaukJ5M","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1601411818400,"user_tz":-180,"elapsed":1166,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"4c3eb7dd-3617-4ebe-9a6b-215008eaf7ea"},"source":["if __name__ == '__main__':\n","  # Чтение первых 12 тыс слов из коллекции Brown\n","  input_data = text\n","  \n","  # Определение количества слов в каждом блоке \n","  chunk_size = 10\n","\n","  chunks = chunker(input_data, chunk_size)\n","  print('\\nNumber of text chunks =', len(chunks), '\\n')\n","  for i, chunk in enumerate(chunks):\n","    print('Chunk', i+1, '==>', chunk[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Number of text chunks = 28 \n","\n","Chunk 1 ==> \n","Long Shor\n","Chunk 2 ==> designed t\n","Chunk 3 ==> This is ac\n","Chunk 4 ==> inside the\n","Chunk 5 ==> back on it\n","Chunk 6 ==> every feed\n","Chunk 7 ==> the previo\n","Chunk 8 ==> the loopin\n","Chunk 9 ==> over time \n","Chunk 10 ==> neural net\n","Chunk 11 ==> time serie\n","Chunk 12 ==> past. By s\n","Chunk 13 ==> recurrent \n","Chunk 14 ==> as well as\n","Chunk 15 ==> or a thous\n","Chunk 16 ==> to write m\n","Chunk 17 ==> a default \n","Chunk 18 ==> to use LST\n","Chunk 19 ==> and perhap\n","Chunk 20 ==> stock pric\n","Chunk 21 ==> pre formed\n","Chunk 22 ==> called Alp\n","Chunk 23 ==> stocks for\n","Chunk 24 ==> high, low,\n","Chunk 25 ==> from today\n","Chunk 26 ==> better, a \n","Chunk 27 ==> my free AP\n","Chunk 28 ==> daily stoc\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3YjFdKfmkJzm"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-ibHyFkjsCg"},"source":["# Извлечение частотности слов с помощью модели Bag of words"]},{"cell_type":"code","metadata":{"id":"9MJC-7hQjMvx"},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWbNKfJpIP2h"},"source":["# Количество слов в каждом блоке \n","chunk_size = 800"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qt_LNx5FIaGi"},"source":["input_data = ' '.join(brown.words()[:5400])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrdQfi9NHyzT"},"source":["text_chunks = chunker(input_data, chunk_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LikIWAECIeFe"},"source":["# Преобразование в элементы словаря\n","chunks = []\n","for count, chunk in enumerate(text_chunks):\n","    d = {'index': count, 'text': chunk}\n","    chunks.append(d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYymZ2K7Ih1R"},"source":["# Извлечение терм-документной матрицы\n","count_vectorizer = CountVectorizer(min_df=7, max_df=20)\n","document_term_matrix = count_vectorizer.fit_transform([chunk['text'] for chunk in chunks])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QblPFRtQJKvn","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1601439185233,"user_tz":-180,"elapsed":730,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"44e086d1-d57b-44c5-db55-f5852fc12589"},"source":["document_term_matrix"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<7x21 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 147 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"id":"ipVEIOMvItlZ","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1601439185640,"user_tz":-180,"elapsed":764,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"9e01e35c-f412-4961-957f-10d2ce975e05"},"source":["# извлечение и отображение словаря\n","vocabulary = np.array(count_vectorizer.get_feature_names()) \n","print(\"\\nVocabulary:\\n\", vocabulary)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Vocabulary:\n"," ['and' 'are' 'be' 'by' 'county' 'for' 'in' 'is' 'it' 'of' 'on' 'one'\n"," 'said' 'state' 'that' 'the' 'to' 'two' 'was' 'which' 'with']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pOO1-wIRJQ_P"},"source":["# Генерация имен блоков \n","chunk_names = []\n","for i in range(len(text_chunks)):\n","  chunk_names.append('Chunk-' + str(i+1) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4a_IvZQ3JdOJ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1601439195237,"user_tz":-180,"elapsed":1212,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"a67470a9-5c95-4e8f-8a68-77cada2efa24"},"source":["chunk_names"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Chunk-1', 'Chunk-2', 'Chunk-3', 'Chunk-4', 'Chunk-5', 'Chunk-6', 'Chunk-7']"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"Yv8ye2M3Jg5h","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1601439195238,"user_tz":-180,"elapsed":747,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"ad2c5ef3-1779-4167-97f9-23b1bb9baad6"},"source":["# Вывод терм-документной матрицы\n","print(\"\\nDocument term matrix:\")\n","formatted_text = '{:>12}' * (len(chunk_names) + 1)\n","print('\\n', formatted_text.format('Word', *chunk_names), '\\n')\n","for word, item in zip(vocabulary, document_term_matrix.T):\n","    # 'item' is a 'csr_matrix' data structure\n","    output = [word] + [str(freq) for freq in item.data]\n","    print(formatted_text.format(*output))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Document term matrix:\n","\n","         Word     Chunk-1     Chunk-2     Chunk-3     Chunk-4     Chunk-5     Chunk-6     Chunk-7 \n","\n","         and          23           9           9          11           9          17          10\n","         are           2           2           1           1           2           2           1\n","          be           6           8           7           7           6           2           1\n","          by           3           4           4           5          14           3           6\n","      county           6           2           7           3           1           2           2\n","         for           7          13           4          10           7           6           4\n","          in          15          11          15          11          13          14          17\n","          is           2           7           3           4           5           5           2\n","          it           8           6           8           9           3           1           2\n","          of          31          20          20          30          29          35          26\n","          on           4           3           5          10           6           5           2\n","         one           1           3           1           2           2           1           1\n","        said          12           5           7           7           4           3           7\n","       state           3           7           2           6           3           4           1\n","        that          13           8           9           2           7           1           7\n","         the          71          51          43          51          43          52          49\n","          to          11          26          20          26          21          15          11\n","         two           2           1           1           1           1           2           2\n","         was           5           6           7           7           4           7           3\n","       which           7           4           5           4           3           1           1\n","        with           2           2           3           1           2           2           3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZOJdqQiKGMM"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HGAytDFWNv5W"},"source":["# Создание  прогнозатора категорий"]},{"cell_type":"code","metadata":{"id":"ndOtZ2fIN1fv"},"source":["from sklearn.datasets import fetch_20newsgroups\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.feature_extraction.text import TfidfTransformer \n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-FEC3qYOLG-"},"source":["# Определение карты категорий\n","category_map = {'talk.politics.misc': 'Politics',\n","'rec.autos': 'Autos', 'rec.sport.hockey': 'Hockey', \n","'sci.electronics': 'Electronics', 'sci.med': 'Medicine'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej2ouS-eOPVZ","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1601439385128,"user_tz":-180,"elapsed":12060,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"aa93339d-fcfe-4d26-eb76-32ffc14c5f18"},"source":["# Получение тренировочного набора данных \n","training_data = fetch_20newsgroups(subset='train',\n","categories=category_map.keys(), shuffle=True, random_state=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ijpI5g_-OUL-","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1601439388179,"user_tz":-180,"elapsed":1098,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"cf842818-aaad-432d-a742-b9bd71af87c0"},"source":["# Создание векторизатора и извлечение счетчиков слов \n","count_vectorizer = CountVectorizer()\n","train_tc = count_vectorizer.fit_transform(training_data.data)\n","print(\"\\nDimensions of training data:\", train_tc.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Dimensions of training data: (2844, 40321)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UPMi0YVWOc1h"},"source":["# Создание  преобразователя tf-idf\n","tfidf = TfidfTransformer()\n","train_tfidf = tfidf.fit_transform(train_tc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghV2kjCLOyTM"},"source":["# Определение тестовых данных \n","input_data = ['You need to be careful with cars when you are driving slippery roads',\n","              'А lot of devices can Ье operated wirelessly',\n","'Players need to Ье careful when they are close to goal posts', \n","'Political debates help us understand the perspectives of both sides']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOfob9NZPNBQ"},"source":["# Обучение мультиномиального байесовского классификатора\n","classifier = MultinomialNB().fit(train_tfidf, training_data.target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"66NJyEt2PPSa"},"source":["# Преобразование входных данных с помощью\n","# векторизатора счетчиков\n","input_tc = count_vectorizer.transform(input_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrFnBuZ4PR6Z"},"source":["# Преобразование векторизованных данных с помощью tf - idf\n","input_tfidf = tfidf.transform(input_tc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHV2p_Z0PX_v"},"source":["# Прогнозирование результирующих категорий\n","predictions = classifier.predict(input_tfidf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPdqiU6WPZ9J","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1601439658601,"user_tz":-180,"elapsed":536,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"9fcac8c6-c7f1-4907-cfa8-46b26723bab6"},"source":["# Вывод результатов\n","for sent, category in zip(input_data, predictions):\n","  print('\\ninput: ', sent, '\\nPredicted category: ',\n","        category_map[training_data.target_names[category]])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","input:  You need to be careful with cars when you are driving slippery roads \n","Predicted category:  Autos\n","\n","input:  А lot of devices can Ье operated wirelessly \n","Predicted category:  Electronics\n","\n","input:  Players need to Ье careful when they are close to goal posts \n","Predicted category:  Hockey\n","\n","input:  Political debates help us understand the perspectives of both sides \n","Predicted category:  Politics\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tMrE3fOaPe_w"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T37uVMBzPgrX"},"source":["# Создание анализатора грамматических родов"]},{"cell_type":"code","metadata":{"id":"YiGBNVYjPjlp"},"source":["import random\n","from nltk import NaiveBayesClassifier\n","from nltk.classify import accuracy as nltk_accuracy\n","from nltk.corpus import names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziTzhH0PPlRc"},"source":["# Извлечение последних N букв из входного слова\n","# и возврат значения, выступающего в качестве \"признака\"\n","def extract_features(word, N=2):\n","  last_n_letters = word [-N:]\n","  return {'feature': last_n_letters .lower()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnm6tIBlQgaU","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1601439928096,"user_tz":-180,"elapsed":836,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"a220ca63-7cf9-413f-ff70-3af44564dd14"},"source":["nltk.download('names')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package names to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/names.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"879bSHEgPz8p"},"source":["if __name__ =='__main__':\n","    # Создание обучающих данных с использованием \n","    # помеченных имен, доступных в NLTK \n","    male_list = [(name, 'male') for name in names.words('male.txt' )] \n","    female_list = [ (name, 'female') for name in names.words('female.txt')] \n","    data = (male_list + female_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJPtcQyyQDeJ"},"source":["# Затравочное значение дпя генератора случайных чисел \n","random.seed(5)\n","# Перемешивание данных \n","random.shuffle(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTTpHVuIQOY1"},"source":["# Создание тестовых данных\n","input_names = ['Alexander', 'Danielle', 'David', 'Cheryl']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LbEmnhvQj0I"},"source":["# Определение количеств образцов, используемых \n","# дпя тренировки и тестирования\n","num_train = int(0.8 * len(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRQUGeGBQmEr","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1601440214240,"user_tz":-180,"elapsed":865,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"3574946b-d270-4c1a-bb90-7a44ca7520f7"},"source":["# Итерирование по различным длинам конечного # фрагмента дпя сравнения точности\n","for i in range(1, 6):\n","  print('\\nNшnЬer of end letters: ', i)\n","  features = [ (extract_features(n, i), gender) for (n,gender) in data]\n","  train_data, test_data = features[:num_train], features[num_train:]\n","  classifier = NaiveBayesClassifier.train(train_data)\n","  # Вычисление точности классификатора\n","  accuracy = round(100 * nltk_accuracy(classifier, test_data), 2) \n","  print('Accuracy = ' + str (accuracy) + ' %' )\n","  # Предсказание результатов для входнь~ имен\n","  # с использованием обученной модели классификатора \n","  for name in input_names:\n","    print(name, '==>', classifier.classify(extract_features(name, i )))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","NшnЬer of end letters:  1\n","Accuracy = 74.7 %\n","Alexander ==> male\n","Danielle ==> female\n","David ==> male\n","Cheryl ==> male\n","\n","NшnЬer of end letters:  2\n","Accuracy = 78.79 %\n","Alexander ==> male\n","Danielle ==> female\n","David ==> male\n","Cheryl ==> female\n","\n","NшnЬer of end letters:  3\n","Accuracy = 77.22 %\n","Alexander ==> male\n","Danielle ==> female\n","David ==> male\n","Cheryl ==> female\n","\n","NшnЬer of end letters:  4\n","Accuracy = 69.98 %\n","Alexander ==> male\n","Danielle ==> female\n","David ==> male\n","Cheryl ==> female\n","\n","NшnЬer of end letters:  5\n","Accuracy = 64.63 %\n","Alexander ==> male\n","Danielle ==> female\n","David ==> male\n","Cheryl ==> female\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wuTcjFCERmii"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uwzit5tKRn-N"},"source":["# Создание сентимент-анализатора"]},{"cell_type":"code","metadata":{"id":"PJRO6c9iRrTt"},"source":["from nltk.corpus import movie_reviews\n","from nltk.classify import NaiveBayesClassifier\n","from nltk.classify.util import accuracy as nltk_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcDSKdzhRvCr"},"source":["# Извлечение признаков из входного списка слов\n","def extract_features(words):\n","  return dict([(word, True) for word in words])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LXa_kU5SExT","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1601440339446,"user_tz":-180,"elapsed":1059,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"2422d29f-6d04-4ba9-8e4c-084d416fd8c1"},"source":["nltk.download('movie_reviews')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":146}]},{"cell_type":"code","metadata":{"id":"o03z0s-ER0CK"},"source":["if __name__ =='__main__':\n","  # Загрузка отзывов из коллекции\n","  fileids_pos = movie_reviews.fileids('pos') \n","  fileids_neg = movie_reviews.fileids('neg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Pn-_eKTR9FM"},"source":["# Извлечение признаков из отзывов\n","features_pos = [ (extract_features(movie_reviews.words(fileids=[f]) ), 'Positive') for f in fileids_pos] \n","features_neg = [ (extract_features(movie_reviews.words(fileids=[f]) ), 'Negative') for f in fileids_neg]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_JJLiuoSJ7d"},"source":["# Определение относительных долей тренировочного # и тестового наборов (80% и 20%)\n","threshold = 0.8\n","num_pos = int(threshold * len(features_pos)) \n","num_neg = int(threshold * len(features_neg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8DxbI_nSZHN"},"source":["# Создание тренировочного и тестового наборов\n","features_train = features_pos[:num_pos] + features_neg[:num_neg]\n","features_test = features_pos[num_pos:] + features_neg[num_neg:]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88my849ySr8L","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1601440541708,"user_tz":-180,"elapsed":1843,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"61fe194b-671d-4358-8f21-ce3d2d934350"},"source":["# Вывод количества используемых точек данных \n","print('\\nNumber of training datapoints: ', len(features_train))\n","print('Number of test datapoints: ', len(features_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Number of training datapoints:  1600\n","Number of test datapoints:  400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kan6yuNRS0sx","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1601440575909,"user_tz":-180,"elapsed":3421,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"4ff6454d-8ca4-4a91-f570-2cdba1fe874c"},"source":["# Обучение наивного байесовского классификатора \n","classifier = NaiveBayesClassifier.train(features_train)\n","print('\\nAccuracy of the classifier: ', nltk_accuracy(classifier, features_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Accuracy of the classifier:  0.735\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6KrcctheS8tU","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1601440659567,"user_tz":-180,"elapsed":1069,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"fc2e830a-cc25-4d24-b109-44adf479c7ff"},"source":["N= 15\n","print('\\nTop ' + str(N) + 'most inforrnative words: ') \n","for i, item in enumerate(classifier.most_informative_features()): \n","  print(str(i+1) + '. ' + item[0])\n","  if i == N-1:\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Top 15most inforrnative words: \n","1. outstanding\n","2. insulting\n","3. vulnerable\n","4. ludicrous\n","5. uninvolving\n","6. astounding\n","7. avoids\n","8. fascination\n","9. seagal\n","10. darker\n","11. anna\n","12. symbol\n","13. affecting\n","14. animators\n","15. idiotic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4zVa4ECBTJBt"},"source":["# Тестирование входных отзывов о фильмах \n","input_reviews = [\n","'The costumes in this rnovie were great',\n","'I think the story was terriЫe and the characters were very weak',\n","'People say that the director of the movie is amazing', \n","'This is such an idiotic movie. I will not recornrnend it to anyone.']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTl3Z3HfTdoX","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1601440936756,"user_tz":-180,"elapsed":553,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"d58abd30-9030-408d-89e8-6c3417c317ab"},"source":["print(\"\\nMovie review predictions:\")\n","for review in input_reviews: \n","  print(\"\\nReview:\", review)\n","  # вычисление вероятностей\n","  probabilities = classifier.prob_classify(extract_features(review.split())) \n","  # выбор макс знач-я\n","  predicted_sentiment = probabilities.max()\n","  # вывод рез-ов\n","  print(\"Predicted sentiment\", predicted_sentiment)\n","  print(\"Probability\", round(probabilities.prob(predicted_sentiment),2))  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Movie review predictions:\n","\n","Review: The costumes in this rnovie were great\n","Predicted sentiment Positive\n","Probability 0.61\n","\n","Review: I think the story was terriЫe and the characters were very weak\n","Predicted sentiment Negative\n","Probability 0.58\n","\n","Review: People say that the director of the movie is amazing\n","Predicted sentiment Positive\n","Probability 0.6\n","\n","Review: This is such an idiotic movie. I will not recornrnend it to anyone.\n","Predicted sentiment Negative\n","Probability 0.89\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BTTMq6QZUj9Y"},"source":["# Тематическое моделирование с использованием Латентного размещения Дирихле"]},{"cell_type":"code","metadata":{"id":"NTv3twBWTvgD"},"source":["from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer \n","from gensim import models, corpora"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Om0Udwx1Usrv"},"source":["# Загрузка входных данных \n","def load_data(input_file):\n","  data = []\n","  with open(input_file, 'r') as f:\n","    for line in f.readlines(): \n","      data.append(line[:-1])\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iBR3IDiUzMZ"},"source":["# Функция обработки, предназначенная дnя токенизации текста,\n","# удаления стоп-слов и выполнения стемминга\n","def process(input_text):\n","  # Создание регулярного выражения для токенизатора\n","  tokenizer = RegexpTokenizer(r'\\w+')\n","  # Создание стеммера Сноубаолла\n","  stemmer = SnowballStemmer('english')\n","  # Получение списка стоп-слов\n","  stop_words = stopwords.words('english')\n","  # Токенизация входной строки\n","  tokens = tokenizer.tokenize(input_text.lower())\n","  # Удаление стоп-слов\n","  tokens = [х for х in tokens if not х in stop_words]\n","  # Вьmолнение стемминга токенизированных слов\n","  tokens_stemmed = [stemmer.stem(x) for x in tokens] \n","  return tokens_stemmed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sf7IkgUmYc4l","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1601442011065,"user_tz":-180,"elapsed":682,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"bd4c39fe-e4cb-4f8b-b088-8ffd2b1e1edc"},"source":["nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"_ij9Cx7cVXhL","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1601442297321,"user_tz":-180,"elapsed":601,"user":{"displayName":"Ардан Доржиев","photoUrl":"","userId":"12616677815845703401"}},"outputId":"6bd98a26-add0-4a4f-87a9-03abbb2fee06"},"source":["if __name__ =='__main__':\n","  # Загрузка входных данных \n","  data = load_data('data.txt')\n","  # Создание списка токенов предложений \n","  tokens = [process(x) for x in data]\n","  # Создание словаря на основе токенизированных предложений \n","  dict_tokens = corpora.Dictionary(tokens)\n","  # Создание терм-документной матрицы\n","  doc_term_mat = [dict_tokens.doc2bow(token) for token in tokens]\n","  # Определим количество тем для LDА-модели \n","  num_topics = 2\n","  # Генерирование LDА-модели\n","  ldamodel = models.ldamodel.LdaModel(doc_term_mat, num_topics=num_topics, id2word=dict_tokens, passes=25)\n","  num_words = 5\n","  print('\\nTop ' + str(num_words) + ' contributing words to each topic:')\n","  for item in ldamodel.print_topics(num_topics=num_topics, num_words=num_words):\n","    print('\\nTopic', item[0])\n","  # Вывод представительных слов вместе с их # относительными вкладами\n","  list_of_strings = item[1] .split(' + ') \n","  for text in list_of_strings:\n","    weight = text.split('*') [0]\n","    word = text.split('*') [1]\n","    print(word, '==>', str(round(float(weight) * 100, 2)) + '%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Top 5 contributing words to each topic:\n","\n","Topic 0\n","\n","Topic 1\n","\"empir\" ==> 3.8%\n","\"time\" ==> 2.7%\n","\"peopl\" ==> 2.7%\n","\"histor\" ==> 2.7%\n","\"expand\" ==> 2.7%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CL8mJX_6WFpH"},"source":[],"execution_count":null,"outputs":[]}]}